---
title: "R Markdown"
author: "Swati Bhargava"
date: "12/01/2022"
output: 
  html_document:
    css: bootstrap_2.css
    
---    


## **1. Question 1 – Predicting Customers Who Will Renew Their Music Subscription**

### ***1.	Import the sub_training.csv and sub_testing.csv datasets into R.***


```{r, message = F, comment = F, warning = F, collapse = T}

# Loading all necessary libraries
library(tidyverse)
library(kableExtra)
library(gridExtra)
library(cluster)
library(rattle)
library(rpart)
library(gghighlight)

# Importing the Training and Test datasets
sub_training <- read_csv("sub_training.csv")
sub_testing <- read_csv("sub_testing.csv")

```


### ***2. Using the sub_training.csv dataset, carry out a visual exploration of the data to understand the relationship between whether or not a customer renews their subscription (variable called “Renewed”) and each of the other potential predictor variables. Comment on your findings.***

```{r, message = F, comment = F, warning = F, collapse = T}

# Relationship between variable "Renewed" and "Gender"

# Create an dataframe with total counts across each gender
gender_distribution <- sub_training %>% group_by(gender) %>% summarise(total_count = n())


# Create an dataframe with total counts across each gender and renewal variable
renewal_by_gender <- sub_training %>% group_by(gender, renewed) %>% summarise(count = n())


# Merge the 2 dataframes created above to get all the required data into one dataset
merged_data <- merge(gender_distribution, renewal_by_gender, by = "gender")


# Create a percentage column to calculate percentage across each group
merged_data$percentage <- round(merged_data$count/merged_data$total_count*100)


# plot the data on a clustered bar graph
ggplot(merged_data, aes(x = renewed, y = percentage, fill = gender)) +
  geom_col(position = "dodge") +
  labs(title = "Percentage distribution of Customers", 
       x = "Renewal Status",
       y = "Percentage") +
  geom_text(
    aes(label = paste(percentage,"%",sep = "")),
    colour = "white", size = 4,
    vjust = 1.5, position = position_dodge(.9)
  ) +
  scale_fill_manual(values = c("#8B2E39","grey")) +
  theme(legend.title = element_blank())

```


As the graph shows 57% of the females did not renew their subscription where as only 46% of the males did not renew their subscription. So, majority of the females did not renew compared to their male counterparts.

Now let's check the distribution of Spend, Length of Relationship, Number of contacts, Number of complaints, Contact Recency and Age across their renewal status.

```{r, message = F, comment = F, warning = F, collapse = T}

# Boxplot of Renewal Status Vs Spend
p1 <- sub_training %>% 
  ggplot(aes(x = renewed, y = spend))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")

# Boxplot of Renewal Status Vs Lor (length of relationship)
p2 <- sub_training %>% 
  ggplot(aes(x = renewed, y = lor))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")

# Boxplot of Renewal Status Vs Number of complaints
p3 <- sub_training %>% 
  ggplot(aes(x = renewed, y = num_complaints))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")

# Boxplot of Renewal Status Vs Number of times contacted the music company
p4 <- sub_training %>% 
  ggplot(aes(x = renewed, y = num_contacts))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")

# Boxplot of Renewal Status Vs Contact Recency
p5 <- sub_training %>% 
  ggplot(aes(x = renewed, y = contact_recency))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")

# Boxplot of Renewal Status Vs Age
p6 <- sub_training %>% 
  ggplot(aes(x = renewed, y = age))+
  geom_boxplot(position = "dodge2", color = "black") +
  stat_summary(fun.y="mean", 
               geom="point", 
               size=1,
               position=position_dodge(width=0.75), 
               color="black")


# Arranging all the above graphs in a grid format with 2 columns
grid.arrange(p1,p2,p3,p4,p5,p6, ncol = 2)

```

The first graph shows that the mean spend of those who did not renew is around 290 where as the median is around 320. On the contrary the mean spend of those customers who renewed their subscription is higher i.e. around 340-350 and median is even higher i.e. around 400.

The mean length of relationship is higher around 175 days for those who have renewed as opposed to those who haven't (mean lor of around 135). However, there are many outliers which means there were customers who have been with the company for a long time but still they didn't renew their subscription.

Number of complaints does not seem to make much of a difference, as both the groups have similar number of outliers approximately.

The average number of contacts seems higher for those who renewed vs those who didn't. 

The customers who didn't renew seem to have not contacted the company recently with majority of them last contacted around 14-28 days back, where as those who have renewed seems to be in touch with the company with a majority in a window of 7-28 days back. The means also indicate a similar picture, however there is a very slight difference between the mean for non-renewing customers (around 21days back) as compared to those who renewed (around 19days back).

The last graph in the grid is indicating that on an average age of customers renewed successfully was around 57/58 while the mean age of people who didn't renew was around 55 which is not a substantial difference in the age.


### ***3. Create and visualise a classification tree model that will allow you to predict if a customer will re-subscribe or churn.***

```{r, message = F, comment = F, warning = F, collapse = T}

# creating a classification tree with renewal status as the dependent variable and all other variables as independent variables
sub_tree <- rpart(renewed ~ spend + lor + num_complaints + num_contacts + contact_recency + gender + age , sub_training)
fancyRpartPlot(sub_tree)

```

### ***4.	Interpret the classification tree***

a.	Clearly state one rule for predicting if a customer will re-subscribe. Your answer should also address how pure the node is.

**Ans: If a customer has stayed with the company for 140 days or more (i.e. lor >= 140) then it can be said that the customer will re-subscribe. This statement can be said with an accuracy of 61% only i.e. if the customer has stayed with the company for 140 days or more there is a 61% probability that the customer will renew their subscription.**


b.	Clearly state one rule for predicting if a customer will churn. Your answer should also address how pure the node is.

**Ans: A customer is not likely to re-subscribe if the customer has stayed with the company for less than 140 days and their overall spend in last 36 months is less than 182. This node has an accuracy of 76% which also means that there is 76% chance that a customer will not renew their subscription if they have stayed with the company for 140 days or less.**

```{r, message = F, comment = F, warning = F, collapse = T}

#Extract the variable importance from the rpart object
sub_tree$variable.importance

#Extract the variable importance as a percentage of all improvements to the model
summary(sub_tree)

```

c.	Which variables are considered important for predicting if a customer will re-subscribe or not? Explain your answer.

**Ans: The most important variable is lor (length of relationship) with 47% importance, followed by spend and age each having an importance of 22%. Number of contacts and Contact recency are less important with an importance value of 8% and 1% respectively. Variables which have an importance of less than 1% are not included in the tree which in this case are number of complaints (num_complaints) and gender.**


### ***5.	Fully assess the accuracy of the classification tree using both the training and the testing datasets.***

```{r, message = F, comment = F, warning = F, collapse = T}

#Measure accuracy on Training data

train_probs <- predict(sub_tree, newdata = sub_training, type = 'prob')
train_preds <- predict(sub_tree, newdata = sub_training, type = 'class')

sub_training_updated <- cbind(sub_training, train_probs, train_preds)
#head(sub_training_updated)

train_con_mat <- table(sub_training_updated$renewed, sub_training_updated$train_preds, dnn=c('Actual', 'Predicted'))
train_con_mat

#Measure accuracy on Testing data

test_probs <- predict(sub_tree, newdata = sub_testing, type = 'prob')
test_preds <- predict(sub_tree, newdata = sub_testing, type = 'class')
sub_testing_updated <- cbind(sub_testing, test_probs, test_preds)
#head(sub_testing_updated)

test_con_mat <- table(sub_testing_updated$renewed, sub_testing_updated$test_preds, dnn = c('Actual', 'Predicted'))
test_con_mat

```

**Ans: Based on the above confusion matrix for training dataset -**  

* **The overall model accuracy is (257 + 270)/850 = 0.62 or 62%.**
* **Of all customers the model predicted to re-subscribe, they got 270/439 = 0.62 or 62% correct.**
* **Of all customers the model predicted to not re-subscribe, they got 257/411 = 0.63 or 63% correct.**
* **Of all customers who did re-subscribe, the model correctly identified 270/424 = 0.64 or 64%.**
* **Of all customers who did not re-subscribe, the model correctly identified 257/426 = 0.60 or 60%.**

**Based on the above confusion matrix for test dataset -**  

* **The overall model accuracy is (36 + 41)/150 = 0.51 or 51%.**
* **Of all customers the model predicted to re-subscribe, they got 41/79 = 0.53 or 53% correct.**
* **Of all customers the model predicted to not re-subscribe, they got 36/71 = 0.51 or 51% correct.**
* **Of all customers who did re-subscribe, the model correctly identified 41/76 = 0.54 or 54%.**
* **Of all customers who did not re-subscribe, the model correctly identified 36/74 = 0.49 or 49%.**


a.	Based on your findings, you should see evidence of the classification tree overfitting the training dataset. Explain how this overfitting is detected.

**Ans: As explained above the overall model accuracy is different for training (62%) and test (51%) datasets. Infact, this is seen across all the five measures showing are less accuracy for the test dataset. This indicates that the classification tree is overfitting the training dataset, as the accuracy is more for the training dataset when compared to the test dataset. Hence we need to consider pruning the tree for better better prediction on the test dataset.**


b.	Create a second classification tree that is a pruned version of the classification tree created in part 2. This pruned classification tree should have a max depth of 3.
```{r, message = F, comment = F, warning = F, collapse = T}
#Create and visualise the pruned classification tree
sub_tree2 <- rpart(renewed ~ spend + lor + num_complaints + num_contacts + contact_recency + gender + age, sub_training, maxdepth = 3)
fancyRpartPlot(sub_tree2)

```

c.	Fully assess the accuracy of the pruned tree on the training and testing datasets.

```{r, message = F, comment = F, warning = F, collapse = T}
# Measure accuracy on Training data

train_probs2 <- predict(sub_tree2, newdata = sub_training, type = 'prob')
train_preds2 <- predict(sub_tree2, newdata = sub_training, type = 'class')
sub_training_updated2 <- cbind(sub_training, train_probs2, train_preds2)

train_con_mat2 <- table(sub_training_updated2$renewed, sub_training_updated2$train_preds, dnn = c('Actual', 'Predicted'))
train_con_mat2
sum(diag(train_con_mat2))/sum(train_con_mat2)


# Measure accuracy on Testing data

test_probs2 <- predict(sub_tree2, newdata = sub_testing, type = 'prob')
test_preds2 <- predict(sub_tree2, newdata = sub_testing, type = 'class')
sub_testing_updated2 <- cbind(sub_testing, test_probs2, test_preds2)

test_con_mat2 <- table(sub_testing_updated2$renewed, sub_testing_updated2$test_preds, dnn = c('Actual', 'Predicted'))
test_con_mat2
sum(diag(test_con_mat2))/sum(test_con_mat2)

```

**Ans: Based on the above revised confusion matrix of the pruned tree for training dataset-**  

* **The overall model accuracy is (266 + 252)/850 = 0.61 or 61%.**
* **Of all customers the model predicted to re-subscribe, they got 252/412 = 0.61 or 61% correct.**
* **Of all customers the model predicted to not re-subscribe, they got 266/438 = 0.61 or 61% correct.**
* **Of all customers who did re-subscribe, the model correctly identified 252/424 = 0.59 or 59%.**
* **Of all customers who did not re-subscribe, the model correctly identified 266/426 = 0.62 or 62%.**


**Based on the above confusion matrix for test dataset-**

* **The overall model accuracy is (41 + 38)/150 = 0.53 or 53%.**
* **Of all customers the model predicted to re-subscribe, they got 38/71 = 0.535 or 53.5% correct.**
* **Of all customers the model predicted to not re-subscribe, they got 41/79 = 0.52 or 52% correct.**
* **Of all customers who did re-subscribe, the model correctly identified 38/76 = 0.50 or 50%.**
* **Of all customers who did not re-subscribe, the model correctly identified 41/74 = 0.55 or 55%.**



d.	Has pruning the classification tree resulted in less overfitting? Explain your answer.

**Ans: Yes, the pruning resulted in less overfitting as the overall accuracy of the model for testing dataset improved from 51% to 53% and that of training dataset reduced from 62% to 61%. This might be a slight improvement but this improvement indicates that the overfitting is reduced and the model should predict new data more accurately.**



### ***6.	Based on your analysis, suggest some actions the company could take to improve their renewal rate. How could your propensity model be used for marketing purposes?***

**Ans: As the pruned classification tree suggests that if the customer have stayed with the company for 140 days or less but their spend is more than 182, then connecting with them or contacting them more often (>7.5 times) can actually lead them to renew their subscription with an accuracy of 68%. So pro-actively getting in touch with these segment of customers who might be at the fence can really help in customer retention.**





## **2. Question 2 – Segmenting Consumers Based on Energy Drink Preference**

### ***1.	Import the energy_drinks.csv file into R.***

```{r, message = F, comment = F, warning = F, collapse = T}

# Importing the energy_drinks dataset
energy_drinks <- read_csv("energy_drinks.csv")

```

### ***2.	Create a distance matrix containing the Euclidean distance between all pairs of consumers.***

```{r, message = F, comment = F, warning = F, collapse = T}

# Compute the distance matrix
energy_drinks_2 <- select(energy_drinks, D1, D2, D3, D4, D5)
d1 <- dist(energy_drinks_2)

```

a.	Does the data need to be scaled before computing the distance matrix? Explain your answer. 

**Ans: No, the data doesn't need to be scaled as all the customer ratings data for variants D1 to D5 are measured on the same likert scale of 1 to 9. So all the variables D1 to D5 used for clustering have same scale or unit of measurement.**


### ***3.	Carry out a hierarchical clustering using the hclust function. Use method = "average". ***
```{r, message = F, comment = F, warning = F, collapse = T}

#Step 3: Carry out the hierarchical clustering. Using average method
h1 <- hclust(d1, method = "average")

```

### ***4.	Visualise the results of the hierarchical clustering using a dendrogram and a heatmap. Note that the heatmap may take several seconds to appear because of the large number of customers in the dataset.***

```{r, message = F, comment = F, warning = F, collapse = T}
# plotting the dendrogram and heatmap
plot(h1, hang = -1)
heatmap(as.matrix(d1), Rowv = as.dendrogram(h1), Colv = 'Rowv')

```

a.	Does the heatmap provide evidence of any clustering structure within the energy drinks dataset? Explain your answer.

**Ans: Yes, both the heatmap and dendrogram show a possibility of three major clusters within the energy drink dataset. From the dendrogram, if we draw a horizontal line at a height of around 5.9 or 6 then this line cuts three vertical lines in the dendrogram,which indicates the three inherent clusters. Similarly, on looking at the heatmap,we can see three major light yellow coloured squares around the diagonal from top-left to bottom-right. The centre square represents a larger cluster while the other two are smaller in size representing the number of customers in each cluster.**


### ***5.	Create a 3-cluster solution using the cutree function and assess the quality of this solution.***
```{r, message = F, comment = F, warning = F, collapse = T}
#Step 4: Cutting the tree at k = 3, on number of clusters
clusters3 <- cutree(h1, k = 3)

#Step 5: Assessing the quality of the segmentation
sil <- silhouette(clusters3, d1)
summary(sil)

```

**Ans: Looking at the Silhouette scores above, the overall mean Silhouette score of 0.2550 indicates a weak structure and could be artificial. Moreover, the average Silhouette scores of individual clusters i.e. C1 = 0.22, C2 = 0.19 and C3 = 0.39, are all less than 0.5 which also indicate a weak or no substantial structure.**

### ***6.	Profile the clusters, making sure to include answers to the questions below. Include any graphs/tables necessary to support your profiling.***
a.	How do the clusters differ on their average rating of each version of the energy drinks?
b.	How do the clusters differ on age and gender?
```{r, message = F, comment = F, warning = F, collapse = T}
# Profiling the clusters
energy_drinks_clus <- cbind(energy_drinks, clusters3)
energy_drinks_clus <- mutate(energy_drinks_clus, cluster = case_when(clusters3 == 1 ~ 'C1',
                                                 clusters3 == 2 ~ 'C2',
                                                 clusters3 == 3 ~ 'C3'))

# Create a table showing the size of each segment (i.e the number of customers in the cluster) and the average rating of each version of the energy drinks.

size_rating <- energy_drinks_clus %>%
  group_by(cluster) %>%
  summarise(num_customers = n(),
            avg_rating_D1 = round(mean(D1)),
            avg_rating_D2 = round(mean(D2)),
            avg_rating_D3 = round(mean(D3)),
            avg_rating_D4 = round(mean(D4)),
            avg_rating_D5 = round(mean(D5)))

knitr::kable(size_rating,
             align = "lrrrrrr",
             col.names = c("Cluster", 
                           "Number of Customers", 
                           "Avg D1 Rating",
                           "Avg D2 Rating",
                           "Avg D3 Rating",
                           "Avg D4 Rating",
                           "Avg D5 Rating"),
             caption = "Average Ratings of the 5 variation of energy drinks across the 3 Clusters") %>%
  kable_styling(full_width = F) %>%
  row_spec(0, bold = T, color = "#630001", background = "gray")

# Convert the dataset to be in "tidy" format to allow for creation of boxplots.
tab_clus_tidy <- size_rating %>%
  pivot_longer(cols = c(avg_rating_D1, 
                        avg_rating_D2, 
                        avg_rating_D3, 
                        avg_rating_D4, 
                        avg_rating_D5), 
               names_to = c("avg","rating","energy_variant"), values_to = "avg_rating",
               names_sep = "\\_")

tab_clus_tidy <- tab_clus_tidy[,-3:-4] # removing columns 3 and 4 which were not relevant

#Visualise the mean rating for each variation by cluster.

tab_clus_tidy %>% 
  ggplot(aes(x = energy_variant, y = avg_rating, fill = cluster))+
  geom_col(position = "dodge2", color = "black") +
  labs(title = "Average Customer Ratings for each Cluster across different Energy Drink Variants", 
       x = "Energy Variant",
       y = "Average Rating") +
  guides(fill=guide_legend(title="Clusters")) +
  scale_fill_manual(values = c("#E9DCD6","#FED0BB","#8B2E39")) +
  theme(panel.background = element_blank()) +
  geom_text(aes(label = avg_rating),
            color = "#630001",
            position = position_dodge(0.9),
            vjust = -0.2) +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.background = element_blank())


```

**From the above graph we can conclude that the variations preferred by the customers in each clusters are as follows -**
**1. Cluster 1 preferred D4 and D5 the most closely followed by D3.**
**2. Cluster 2 preferred D3 the most.**
**3. Cluster 3 preferred D1 the most.**

```{r, message = F, comment = F, warning = F, collapse = T}
# How do the clusters differ on age and gender.

# Converting age into ordinal variable
energy_drinks_clus$Age <- factor(energy_drinks_clus$Age,levels = c("Under_25",
                                            "25_34",
                                            "35_49",
                                            "50_64",
                                            "Over_65"))

# Grouping the data by Age, Gender and Clusters
summary <- energy_drinks_clus %>%
  group_by(Age, Gender, cluster) %>%
  summarise(count_gender_age = n())


# Visualise a bar chart across age groups and gender for each cluster 

ggplot(summary,
       aes(x = Age,
           y = count_gender_age,
           fill = Gender)) +
  geom_col(width = 0.5,
           position = "dodge") +
  geom_text(stat = "identity",
            position = position_dodge(0.5),
            aes(label = count_gender_age),
            size = 2.5,
            vjust = -0.5,
            hjust = 0.5) + 
  scale_fill_manual(values = c("#8B2E39","grey")) +
  facet_grid(.~cluster, 
             scales = "free",
             space = "free") +
  labs(title = "Customer Ratings for each Cluster across Age groups and Gender", 
       x = "Age Group",
       y = "") +
  theme(axis.text.y = element_blank(),
        axis.ticks.y = element_blank(),
        panel.background = element_blank(),
        legend.title = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1)) 


```

**From the above graph we can conclude that -**
**1. Cluster 1 is the biggest cluster with more males than females and maximum customers belong to the age group of 25 to 34 years of age.**
**2. Cluster 2 also has more males than females and majority fall under the same age group 25-34 years.**
**3. Cluster 3 also has more males than females and majority fall under the same age group of 25-34 years.**


### ***7.	Advise the company on the suitable segment/cluster at which to advertise energy drink versions D1, D3 and D5.***

**Ans: As per the conclusions drawn above, the suitable clusters or customer segments to advertise energy drink versions are**-
**1. D1 should be advertised to Cluster 3 **
**2. D3 should be advertised to Cluster 2 **
**3. D5 should be advertised to Cluster 1 **


### ***8.	If the company had to choose just one version of the energy drink to continue producing, then which one do you recommend and why?***

**Ans: As per the conclusions drawn from above data it would be beneficial for the company to continue producing version D5 which is preferred by Cluster 1 which is the largest segment in size so there is more potential of gaining customers from this cluster, also as majority of the segment fall under the age group of 25-49 years which are suppose to have the maximum possible disposable income, there is a potential to drive more profit from this customer segment.**

------------------------------------------------------X-----------------------------------------------------